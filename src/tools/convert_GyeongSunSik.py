import asyncio
import json
import re
from typing import List, Dict

from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_teddynote.models import get_model_name, LLMs

from ..utils.state import State

GPT4oMINI = get_model_name(LLMs.GPT4o_MINI)
llm = ChatOpenAI(temperature=1, model=GPT4oMINI)

async def convert_GyeongSunSik_chunk(chunk: List[Dict]) -> List[Dict]:
    prompt = PromptTemplate.from_template("""
    ë‹¹ì‹ ì€ "ê²½ì„ ì‹ ì˜ë‹¨ì–´"ë¥¼ ì´í•´í•˜ê³  í•™ìŠµìžì—ê²Œ ë‹¨ì–´ë¥¼ ì„¤ëª…í•˜ê±°ë‚˜ ì—°ìƒë²•ì„ ë§Œë“¤ì–´ì£¼ëŠ” AIìž…ë‹ˆë‹¤. ì´ ë°©ë²•ì€ í•œêµ­ì˜ ì˜ì–´ ê°•ì‚¬ ê²½ì„ ì‹ì´ ê°œë°œí•œ ê²ƒìœ¼ë¡œ, ì—°ìƒë²•ê³¼ í•´ë§ˆí•™ìŠµë²•ì„ í™œìš©í•´ ë‹¨ì–´ë¥¼ ë¹ ë¥´ê³  ì˜¤ëž˜ ê¸°ì–µí•˜ê²Œ í•©ë‹ˆë‹¤. ì•„ëž˜ ì§€ì¹¨ì„ ë”°ë¼ ìž‘ë™í•˜ì„¸ìš”.

#### ê²½ì„ ì‹ ì˜ë‹¨ì–´ì˜ í•µì‹¬ ì›ë¦¬:
1. ##ì¤‘ìš”## **ì—°ìƒë²•**: ë‹¨ì–´ì˜ ëœ»ì„ ë¹„ìŠ·í•œ ë°œìŒì´ë‚˜ ìœ ë¨¸ëŸ¬ìŠ¤í•œ ì´ì•¼ê¸°ë¡œ ì—°ê²°í•´ ê¸°ì–µì„ ë•ìŠµë‹ˆë‹¤.
ì˜ˆ:
- "senior" (ì„ ë°°) â†’ "ì„ ë°°ëŠ” ì‹ ì´ì—¬!"
- "hope" (í¬ë§) â†’ "í˜¸í”„ì§‘ì—ì„œ í¬ë§ì„ ì°¾ë‹¤"
#ì¤‘ìš”## - ì—°ìƒì€ í•œêµ­ì–´ ë°œìŒì´ë‚˜ ë¬¸í™”ì  ë§¥ë½ì„ í™œìš©í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

2. **íŠ¹ì§•**:
- ìž¬ë¯¸ìžˆê³  ê³¼ê°í•œ í‘œí˜„ ê°€ëŠ¥ (ì €ì†í•œ í‘œí˜„ì€ í”¼í•¨).
- í•™ìŠµìžê°€ ë‹¨ì–´ì™€ ì—°ìƒì„ ì‰½ê²Œ ë– ì˜¬ë¦¬ë„ë¡ ë‹¨ìˆœí•˜ê³  ê°•ë ¬í•˜ê²Œ.

#### ìž‘ì—… ì§€ì¹¨:
1. ë‹¨ì–´ë¥¼ ìž…ë ¥ë°›ìœ¼ë©´, ëœ»ê³¼ ë°œìŒì„ í™•ì¸í•œ ë’¤ ê²½ì„ ì‹ ìŠ¤íƒ€ì¼ì˜ ì—°ìƒë²•ì„ ë§Œë“¤ì–´ ì¶œë ¥í•˜ì„¸ìš”. ìž…ì¶œë ¥ ì˜ˆì‹œëŠ” ì•„ëž˜ ####ì˜ˆì‹œ í•­ëª©ì„ ì°¸ê³ í•˜ì„¸ìš”.

2. **ì£¼ì˜ì‚¬í•­**:
- ì—°ìƒì€ í•œêµ­ì–´ ê¸°ë°˜ìœ¼ë¡œ, ë°œìŒì´ë‚˜ ëœ»ì„ ìžì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°.
- ì§€ë‚˜ì¹˜ê²Œ ë³µìž¡í•˜ê±°ë‚˜ ì–µì§€ìŠ¤ëŸ½ì§€ ì•Šê²Œ, í•™ìŠµìžê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìžˆë„ë¡.
- ë‹¨ì–´ì˜ ëœ»ì„ ì™œê³¡í•˜ì§€ ë§ˆì„¸ìš”.

ë‹¹ì‹ ì—ê²Œ ì˜ë‹¨ì–´ í˜•ì‹ì˜ ë°ì´í„°ê°€ ìž…ë ¥ë  ìˆ˜ ìžˆê³ , ìž…ë ¥ëœ ì˜ë‹¨ì–´ì˜ í˜ì‹ì„ íŒŒì•…í•œ ë’¤ ë‹¤ìŒ ì¶œë ¥ì˜ˆì‹œì™€ ê°™ì´ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

#### ì¶œë ¥ì˜ˆì‹œ:
  "output": [
    {{
      "word": "perish",
      "meaning": "ì£½ë‹¤",
      "pronunciation": "íŽ˜ë¦¬ì‰¬",
      "phonetic": "Ëˆper.ÉªÊƒ",
      "Part of speech": "",
      "association": "[íŒŒë¦¬ ì‰¬~]",
      "description": "A lifeless corpse lying on the ground with flies buzzing around it, symbolizing death."
    }},
    {{
      "word": "eager",
      "meaning": "ê°„ì ˆížˆ ë°”ë¼ëŠ”",
      "pronunciation": "ì´ê±°",
      "phonetic": "",
      "Part of speech": "",
      "association": "[ì´ê±°] ì‚¬ì£¼ì„¸ìš”.",
      "description": "A small child pointing at a teddy bear in a toy store, clearly begging a parent to buy it."
    }},
    {{
      "word": "cohesion",
      "meaning": "ê²°í•©, í™”í•©",
      "pronunciation": "ì½”í—¤ì…˜",
      "phonetic": "",
      "Part of speech": "",
      "association": "[ì½”]ë¥¼ ë§žëŒ€ê³  ìž…ì„ ê²°í•© [í—¤ì…˜]",
      "description": "A man and woman gently touching noses and kissing, expressing bonding."
    }},
    {{
      "word": "chill",
      "meaning": "ëƒ‰ê¸°, í•œê¸°",
      "pronunciation": "ì¹ ",
      "phonetic": "tÊƒÉªl",
      "Part of speech": "",
      "association": "[ì¹ ]ë„ì˜ ê¸°ì˜¨ìœ¼ë¡œ ë–¨ì–´ì ¸ ìŒ€ìŒ€í•œ ë‚ ì”¨.",
      "description": "A person shivering from the cold beside a thermometer showing 7Â°C."
    }}
  ]
#### ì´ì œ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ jsoní˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥ë¬¼ì„ ë§Œë“¤ë©´ ë©ë‹ˆë‹¤.
{input_document}
    """)

    prompt_llm = prompt | llm
    try:
        response = await prompt_llm.ainvoke({
            "input_document": json.dumps(chunk, ensure_ascii=False)
        })

        raw = response.content.strip()
        if raw.startswith("```json"):
            raw = re.sub(r"^```json\s*", "", raw)
            raw = re.sub(r"\s*```$", "", raw)

        parsed = json.loads(raw)
        if isinstance(parsed, list):
            return parsed
        elif isinstance(parsed, dict):
            return parsed.get("output", [])
        else:
            return []

    except Exception as e:
        print(f"[LLM ì²˜ë¦¬ ì˜¤ë¥˜] {type(e).__name__}: {e}")
        # ì—¬ê¸°ì„œ response.content ì ‘ê·¼ ê¸ˆì§€!
        return []

async def convert_GyeongSunSik_async(state: State) -> State:
    formatted_chunks = state["formatted_chunks"]

    chunk_size = 50
    semaphore = asyncio.Semaphore(7)

    def chunkify(data, size):
        return [data[i:i + size] for i in range(0, len(data), size)]

    chunks = chunkify(formatted_chunks, chunk_size)
    print(f"ðŸ“¦ ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    async def limited_chunk(chunk, idx):
        async with semaphore:
            print(f"ðŸš€ chunk[{idx}] ì²˜ë¦¬ ì¤‘...")
            result = await convert_GyeongSunSik_chunk(chunk)
            print(f"âœ… chunk[{idx}] ê²°ê³¼ {len(result)}ê°œ")
            return result

    results = await asyncio.gather(*[
        limited_chunk(chunk, i) for i, chunk in enumerate(chunks)
    ])

    merged = []
    for i, result in enumerate(results):
        print(f"ðŸ”— chunk[{i}] ë³‘í•© ì¤‘... ({len(result)}ê°œ)")
        merged.extend(result)

    print(f"ðŸ“¦ ì´ ê²°ê³¼ ìˆ˜: {len(merged)}ê°œ")
    state["gss_converted_vocabulary"] = merged
    return state



async def convert_GyeongSunSik(state: State) -> State:
    result = await convert_GyeongSunSik_async(state)
    return result
